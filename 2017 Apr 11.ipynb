{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### MA755 Machine Learning - Chapter 8. Dimensionality Reduction - 11 Apr 2017 \n",
    "\n",
    "These notes are based on, and include images from, [_Hands-On Machine Learning with Scikit-Learn and TensorFlow_](http://shop.oreilly.com/product/0636920052289.do)\n",
    "- by Aurélien Géron\n",
    "- Published by O'Reilly Media, Inc., 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics         as sk_me\n",
    "import sklearn.model_selection as sk_ms\n",
    "import sklearn.datasets        as sk_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Curse of dimensionality \n",
    "\n",
    "You can take the Euclidean distance between two rows (data points) in a data set with all numeric variables by treating the numeric features as the coordinates of the data point:\n",
    "- The maximum distance between two data points (rows) in a data set with `2`   variables is $\\sqrt{2}$\n",
    "- The maximum distance between two data points (rows) in a data set with `100` variables is $\\sqrt{100}=10$\n",
    "- Your data points become sparsely distibuted\n",
    "- There is little difference in the distances between data points (Wikipedia)\n",
    "\n",
    "Dimensionality reduction alleviates some of these (and other problems.)\n",
    "\n",
    "In addition, it is easier to visualize or analyze a dataset with fewer features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Main approaches to dimensionality reduction\n",
    "\n",
    "1. Projection\n",
    "1. Manifold learning\n",
    "\n",
    "[draw a picture]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Projection\n",
    "\n",
    "Projections are used to reduce the number of (numeric) features in a dataset. \n",
    "The goal though is to retain the ability to make correct predictions or gain useful insights from the dataset with this reduced set of variables. \n",
    "The procedure is to treat rows as data points and project them into lower dimensional hyperplanes. \n",
    "We replace these numeric data points with their coordinates they project onto in these hyperplanes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Rows correspond to _data points_ when all features of the dataset/array are numeric. \n",
    "This is the case in the `mydata` numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sk_ds.load_iris()\n",
    "\n",
    "mydata = iris.data[:,0:3]\n",
    "\n",
    "mydata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Each numeric variable is considered a coordinate of the data point. \n",
    "Since we have 3 features then each data point has three coordinates and exists in 3-D space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4],\n",
       "       [ 4.9,  3. ,  1.4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[0:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can project these datapoints onto any lower dimensional hyperplane. \n",
    "\n",
    "There are only two types of lower dimensional hyperplanes: lines and planes.\n",
    "\n",
    "When we project a 3-D data point onto a 2-D plane then we:\n",
    "- associate the 3-D point to the closed point on the 2-D plane\n",
    "- replace the 3 features of the data point with the 2 features/coordinates of the point in the (2-D) plane\n",
    "\n",
    "When we project a 3-D data point onto a 1-D line then we:\n",
    "- associate the 3-D point to the closest point on the 1-D line\n",
    "- replace the 3 features of the data point with the 1 feature/coordinate of the point in the (1-D) line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can define a 2-D plane in many ways. One is to fix one coordinate, for instance the third one, as a constant (for example zero.) Projecting the two data points displayed above onto this 2-D plane gives: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5],\n",
       "       [ 4.9,  3. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[0:2,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can define a 1-D line in many ways. One is to fix two coordinates, for instance the second and third, as constants (for example zero for both.) Projecting the two data points displayed above onto this 1-D line gives: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1],\n",
       "       [ 4.9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[0:2,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The remaining examples will use the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mnist = pickle.load(open( \"mnist.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We'll use a sample of `10,000` rows to avoid problems with Python and the Jupyter kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ndx = np.random.randint(mnist.data.shape[0],\n",
    "                               size=10000)\n",
    "X = mnist.data[sample_ndx,:]\n",
    "y = mnist.target[sample_ndx]\n",
    "(X.shape, \n",
    " y.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Standardize the sample dataset of independent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_centered = X - X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Principal Component Analysis - Projection\n",
    "\n",
    "https://en.wikipedia.org/wiki/Principal_component_analysis\n",
    "\n",
    "- Uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components\n",
    "- __The first principal component has the largest possible variance__ and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. \n",
    "- The resulting vectors are an uncorrelated orthogonal basis set. PCA is sensitive to the relative scaling of the original variables.\n",
    "\n",
    "[draw on the board]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a PCA object to create `10` principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create `X10D` with the best 10 principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X10D = pca.fit_transform(X_centered)\n",
    "X10D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Display the variance explained by each component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0991279 ,  0.07033546,  0.06186628,  0.05340114,  0.04883757,\n",
       "        0.04318485,  0.03250653,  0.02873453,  0.02733597,  0.02361584,\n",
       "        0.02111418,  0.02046112,  0.01744191,  0.01704569,  0.01590814,\n",
       "        0.01468382,  0.01315014,  0.01290656,  0.01201142,  0.01154248,\n",
       "        0.01087343,  0.00989359,  0.00963269,  0.00893746,  0.00883667,\n",
       "        0.00836688,  0.00822974,  0.00783466,  0.00746203,  0.00695514,\n",
       "        0.00662609,  0.00627007,  0.00605541,  0.00590151,  0.0056966 ,\n",
       "        0.00554864,  0.00508467,  0.00485173,  0.00480099,  0.0047245 ,\n",
       "        0.00452729,  0.00447373,  0.0042061 ,  0.00394409,  0.0038295 ,\n",
       "        0.00374948,  0.003653  ,  0.00354462,  0.00331808,  0.00328857,\n",
       "        0.00314304,  0.00309604,  0.00301345,  0.00286261,  0.00282931,\n",
       "        0.00279318,  0.00271388,  0.00253673,  0.00249099,  0.00246821,\n",
       "        0.00241144,  0.00236821,  0.00228115,  0.00223837,  0.00214532,\n",
       "        0.00208436,  0.00198464,  0.00194018,  0.00192087,  0.00189921,\n",
       "        0.00187654,  0.00179719,  0.00176717,  0.00173715,  0.0016883 ,\n",
       "        0.001659  ,  0.00162315,  0.00156365,  0.00146773,  0.0014523 ,\n",
       "        0.00143564,  0.00142157,  0.0013647 ,  0.00134464,  0.00130185,\n",
       "        0.00128595,  0.00126351,  0.00123731,  0.00120213,  0.00119498,\n",
       "        0.0011332 ,  0.00112587,  0.00111447,  0.00107902,  0.00106629,\n",
       "        0.001039  ,  0.00102525,  0.00100901,  0.00099012,  0.00096066])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Display the variance explained by all requested components (taken together):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91577705848156099"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Display the cumulative variance explained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0991279 ,  0.16946336,  0.23132964,  0.28473078,  0.33356836,\n",
       "        0.3767532 ,  0.40925974,  0.43799427,  0.46533024,  0.48894608,\n",
       "        0.51006026,  0.53052138,  0.54796329,  0.56500898,  0.58091712,\n",
       "        0.59560095,  0.60875108,  0.62165764,  0.63366905,  0.64521154,\n",
       "        0.65608497,  0.66597856,  0.67561125,  0.68454871,  0.69338538,\n",
       "        0.70175226,  0.709982  ,  0.71781666,  0.72527869,  0.73223383,\n",
       "        0.73885992,  0.74512999,  0.7511854 ,  0.75708691,  0.76278351,\n",
       "        0.76833216,  0.77341683,  0.77826856,  0.78306954,  0.78779405,\n",
       "        0.79232134,  0.79679507,  0.80100117,  0.80494526,  0.80877476,\n",
       "        0.81252424,  0.81617724,  0.81972186,  0.82303994,  0.8263285 ,\n",
       "        0.82947155,  0.83256758,  0.83558103,  0.83844364,  0.84127295,\n",
       "        0.84406613,  0.84678001,  0.84931675,  0.85180774,  0.85427594,\n",
       "        0.85668739,  0.8590556 ,  0.86133675,  0.86357512,  0.86572044,\n",
       "        0.8678048 ,  0.86978944,  0.87172962,  0.87365049,  0.8755497 ,\n",
       "        0.87742624,  0.87922343,  0.8809906 ,  0.88272775,  0.88441605,\n",
       "        0.88607505,  0.88769821,  0.88926185,  0.89072959,  0.89218188,\n",
       "        0.89361752,  0.89503909,  0.89640379,  0.89774843,  0.89905028,\n",
       "        0.90033623,  0.90159974,  0.90283706,  0.90403918,  0.90523416,\n",
       "        0.90636736,  0.90749324,  0.9086077 ,  0.90968672,  0.91075301,\n",
       "        0.91179201,  0.91281727,  0.91382628,  0.91481639,  0.91577706])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can also request enough principal components to explain 60% of the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 17)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.6)\n",
    "X60P = pca.fit_transform(X_centered)\n",
    "X60P.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Incremental PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_batches    = 50\n",
    "n_components = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inc_pca = IncrementalPCA(n_components=n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n",
      "(200, 784)\n"
     ]
    }
   ],
   "source": [
    "for X_batch in np.array_split(X_centered, n_batches):\n",
    "    print(X_batch.shape)\n",
    "\n",
    "    #inc_pca.partial_fit(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X10C100B = inc_pca.transform(X_centered)\n",
    "X10C100B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomized PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rnd_pca = PCA(n_components=100, svd_solver=\"randomized\")\n",
    "X_reduced = rnd_pca.fit_transform(X_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Kernel PCA - Manifold Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components = 2, \n",
    "                    kernel       = \"rbf\", \n",
    "                    gamma        = 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_fit = rbf_pca.fit_transform(X_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### GridSearch with KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "        (\"kpca\", KernelPCA(n_components=2)),\n",
    "        (\"log_reg\", LogisticRegression())\n",
    "    ])\n",
    "\n",
    "param_grid = [{\n",
    "        \"kpca__gamma\": [0.04],\n",
    "        \"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('kpca', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=None, kernel='linear',\n",
       "     kernel_params=None, max_iter=None, n_components=2, n_jobs=1,\n",
       "     random_state=None, remove_zero_eig=False, tol=0)), ('log_reg', LogisticRegre...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kpca__gamma': [0.04], 'kpca__kernel': ['rbf', 'sigmoid']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_centered, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kpca__gamma': 0.04, 'kpca__kernel': 'sigmoid'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components = 4, kernel=\"rbf\", gamma=0.0433,\n",
    "                    fit_inverse_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_reduced = rbf_pca.fit_transform(X_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_preimage = rbf_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preimage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4355.1372057862372"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(X_centered, X_preimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Locally Linear Embedding (LLE) - Manifold Learning\n",
    "\n",
    "- https://www.cs.nyu.edu/~roweis/lle/papers/lleintro.pdf\n",
    "- https://www.stat.cmu.edu/~cshalizi/350/lectures/14/lecture-14.pdf (TRY THIS ONE)\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.manifold.LocallyLinearEmbedding.html\n",
    "\n",
    "From the text:\n",
    "> Here’s how LLE works: first, for each training instance $x(i)$, the algorithm identifies its k closest neighbors (in the preceding code $k = 10$), then tries to reconstruct $x(i)$ as a linear function of these neighbors. More specifically, it finds the weights $w_{i,j}$ such that the squared distance between x(i) and $\\sum_{i=1}^{m}w_{i,j}x^{(j)}$ is as small as possible, assuming $w_{i,j} = 0$ if $x(j)$ is not one of the $k$ closest neighbors of $x(i)$. Thus the first step of LLE is the constrained optimization problem described in Equation 8-4, where $W$ is the weight matrix containing all the weights $w_{i,j}$. The second constraint simply normalizes the weights for each training instance $x(i)$.\n",
    "\n",
    "Simply summarized:\n",
    "\n",
    "- Create a linear regression for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=5, n_neighbors=10)\n",
    "X_reduced = lle.fit_transform(X_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The reconstruction error is the residual sum of square difference between the data points and the linear estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.1268809682965764e-07"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lle.reconstruction_error_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The end"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
